{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"BERT_eval_single.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b1a2687be3f34be9b4759c5ccc87cd3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_74c381be3d5848a5bd87e61bf71d2fd4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3fe34865ba124e719b7c178917798abf","IPY_MODEL_51e50a85382143129aad8c13869ec07f"]}},"74c381be3d5848a5bd87e61bf71d2fd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fe34865ba124e719b7c178917798abf":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_64bc51fd39aa4544a880c421abfe47b1","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9b0da14d3bd477ca31a9ed13b1d8c04"}},"51e50a85382143129aad8c13869ec07f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc11dadf9bb2423c96b6eb3a0e3dca6d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 15.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e1a5ceeddca42249dfbc2ce659596c2"}},"64bc51fd39aa4544a880c421abfe47b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b9b0da14d3bd477ca31a9ed13b1d8c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc11dadf9bb2423c96b6eb3a0e3dca6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e1a5ceeddca42249dfbc2ce659596c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87c561b9bda945009b0f7c30a74aa4e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_feadb52d6b0f4adbb30064d02d06ce14","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0310900d9bd742f4ae9f6c33147112b5","IPY_MODEL_6d6710c960da40bb969d46c5f70c9398"]}},"feadb52d6b0f4adbb30064d02d06ce14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0310900d9bd742f4ae9f6c33147112b5":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5430e2068ddb4ebb8069dfd7ac97d536","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c25f4f8f1c504bac96d380ed6c79bf12"}},"6d6710c960da40bb969d46c5f70c9398":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea4e42f3fbf248af8d0a53da207b479d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 15.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea1ae702a3df405cafa2da5912631ec1"}},"5430e2068ddb4ebb8069dfd7ac97d536":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c25f4f8f1c504bac96d380ed6c79bf12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea4e42f3fbf248af8d0a53da207b479d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ea1ae702a3df405cafa2da5912631ec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"tgdXO4rHp_vr","colab_type":"code","outputId":"6d120d4a-9b09-4f33-cddc-0876fd17d9e6","executionInfo":{"status":"ok","timestamp":1587287801355,"user_tz":-540,"elapsed":33726,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":523}},"source":["!pip install pytorch_pretrained_bert\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import sys\n","sys.path.append('/content/gdrive/My Drive/Colab Notebooks/byBert')\n","\n","import torch\n","print(torch.__version__)\n","import numpy as np\n","import pickle\n","\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix\n","\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.nn import CrossEntropyLoss, MSELoss\n","\n","from tools import *\n","from multiprocessing import Pool, cpu_count\n","import convert_examples_to_features\n","\n","from tqdm import tqdm_notebook, trange\n","\n","import os\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n","from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","logging.basicConfig(level=logging.INFO)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 29.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.39)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.39)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (1.12.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","1.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s2XU2UI_p_vw","colab_type":"code","colab":{}},"source":["# The input data dir. Should contain the .tsv files (or other data files) for the task.\n","DATA_DIR = \"/content/gdrive/My Drive/Colab Notebooks/byBert/data/\"\n","\n","# Bert pre-trained model selected in the list: bert-base-uncased, \n","# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n","# bert-base-multilingual-cased, bert-base-chinese.\n","BERT_MODEL = 'yelp.tar.gz'\n","\n","# The name of the task to train.I'm going to name this 'yelp'.\n","TASK_NAME = 'yelp'\n","\n","# The output directory where the fine-tuned model and checkpoints will be written.\n","OUTPUT_DIR = f'{DATA_DIR}outputs/{TASK_NAME}/'\n","\n","# The directory where the evaluation reports will be written to.\n","REPORTS_DIR = f'{DATA_DIR}reports/{TASK_NAME}_evaluation_report/'\n","\n","# This is where BERT will look for pre-trained models to load parameters from.\n","CACHE_DIR = f'{DATA_DIR}cache/'\n","\n","# The maximum total input sequence length after WordPiece tokenization.\n","# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n","MAX_SEQ_LENGTH = 128\n","\n","TRAIN_BATCH_SIZE = 24\n","EVAL_BATCH_SIZE = 8\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 1\n","RANDOM_SEED = 42\n","GRADIENT_ACCUMULATION_STEPS = 1\n","WARMUP_PROPORTION = 0.1\n","OUTPUT_MODE = 'classification'\n","\n","CONFIG_NAME = \"config.json\"\n","WEIGHTS_NAME = \"pytorch_model.bin\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcsURXY_p_vy","colab_type":"code","colab":{}},"source":["if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n","        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n","        os.makedirs(REPORTS_DIR)\n","if not os.path.exists(REPORTS_DIR):\n","    os.makedirs(REPORTS_DIR)\n","    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n","    os.makedirs(REPORTS_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaREDbwhp_v0","colab_type":"code","colab":{}},"source":["def get_eval_report(task_name, labels, preds):\n","    mcc = matthews_corrcoef(labels, preds)\n","    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n","    return {\n","        \"task\": task_name,\n","        \"mcc\": mcc,\n","        \"tp\": tp,\n","        \"tn\": tn,\n","        \"fp\": fp,\n","        \"fn\": fn\n","    }\n","\n","def compute_metrics(task_name, labels, preds):\n","    assert len(preds) == len(labels)\n","    return get_eval_report(task_name, labels, preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCrcvIxRp_v2","colab_type":"code","outputId":"c2ef84c7-bd60-4918-e0ee-d258e9b0d6b4","executionInfo":{"status":"ok","timestamp":1587222554601,"user_tz":-540,"elapsed":6064,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained(OUTPUT_DIR + 'vocab.txt', do_lower_case=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file /content/gdrive/My Drive/Colab Notebooks/byBert/data/outputs/yelp/vocab.txt\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uAyl8d04p_v5","colab_type":"code","colab":{}},"source":["processor = BinaryClassificationProcessor()\n","# eval_examples = processor.get_dev_examples(DATA_DIR)\n","\n","## MANUALLY SETTING TEST SENTENCE HERE ##\n","\n","eval_examples = [InputExample(guid=0, text_a='The multiple-link type reciprocating internal combustion engine as claimed in claim 1, wherein a pivot of oscillating motion of the third link is displaceable with respect to the body of the engine, to vary a compression ratio of the engine.', text_b=None, label='1')]\n","\n","####\n","\n","label_list = processor.get_labels() # [0, 1] for binary classification\n","num_labels = len(label_list)\n","eval_examples_len = len(eval_examples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EFZbWQPp_v7","colab_type":"code","colab":{}},"source":["label_map = {label: i for i, label in enumerate(label_list)}\n","eval_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_examples]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIWbih9ip_v9","colab_type":"code","outputId":"8860d737-fadc-4d71-be78-d657a8a158fb","executionInfo":{"status":"ok","timestamp":1587222847186,"user_tz":-540,"elapsed":2979,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":157,"referenced_widgets":["b1a2687be3f34be9b4759c5ccc87cd3d","74c381be3d5848a5bd87e61bf71d2fd4","3fe34865ba124e719b7c178917798abf","51e50a85382143129aad8c13869ec07f","64bc51fd39aa4544a880c421abfe47b1","b9b0da14d3bd477ca31a9ed13b1d8c04","fc11dadf9bb2423c96b6eb3a0e3dca6d","7e1a5ceeddca42249dfbc2ce659596c2"]}},"source":["process_count = cpu_count() - 1\n","if __name__ ==  '__main__':\n","    print(f'Preparing to convert {eval_examples_len} examples..')\n","    print(f'Spawning {process_count} processes..')\n","    with Pool(process_count) as p:\n","        eval_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, eval_examples_for_processing), total=eval_examples_len))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Preparing to convert 1 examples..\n","Spawning 1 processes..\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1a2687be3f34be9b4759c5ccc87cd3d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n-mfVLDBp_v_","colab_type":"code","colab":{}},"source":["all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n","all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n","all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_UXzIMPp_wB","colab_type":"code","colab":{}},"source":["if OUTPUT_MODE == \"classification\":\n","    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n","elif OUTPUT_MODE == \"regression\":\n","    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yvkvzAap_wE","colab_type":"code","outputId":"5accc66c-9065-4b6e-d006-2a70dbee08da","executionInfo":{"status":"ok","timestamp":1587222853701,"user_tz":-540,"elapsed":9464,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["# Load pre-trained model (weights)\n","model = BertForSequenceClassification.from_pretrained(CACHE_DIR + BERT_MODEL, cache_dir=CACHE_DIR, num_labels=len(label_list))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:pytorch_pretrained_bert.modeling:loading archive file /content/gdrive/My Drive/Colab Notebooks/byBert/data/cache/yelp.tar.gz\n","INFO:pytorch_pretrained_bert.modeling:extracting archive file /content/gdrive/My Drive/Colab Notebooks/byBert/data/cache/yelp.tar.gz to temp dir /tmp/tmp2a5idu0y\n","INFO:pytorch_pretrained_bert.modeling:Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ffObNtngp_wD","colab_type":"code","colab":{}},"source":["eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","\n","# Run prediction for full data\n","eval_sampler = SequentialSampler(eval_data)\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5U6k8vSwp_wG","colab_type":"code","outputId":"f8d9f6cd-1923-484d-dba6-28ac5ddbaaac","executionInfo":{"status":"ok","timestamp":1587222853704,"user_tz":-540,"elapsed":9442,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.to(device)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"VjTKdZmap_wI","colab_type":"code","outputId":"c92a7906-c63e-4c80-c7c0-c63d5587a1cc","executionInfo":{"status":"ok","timestamp":1587222853705,"user_tz":-540,"elapsed":9428,"user":{"displayName":"김민수","photoUrl":"","userId":"05313884964355981495"}},"colab":{"base_uri":"https://localhost:8080/","height":157,"referenced_widgets":["87c561b9bda945009b0f7c30a74aa4e8","feadb52d6b0f4adbb30064d02d06ce14","0310900d9bd742f4ae9f6c33147112b5","6d6710c960da40bb969d46c5f70c9398","5430e2068ddb4ebb8069dfd7ac97d536","c25f4f8f1c504bac96d380ed6c79bf12","ea4e42f3fbf248af8d0a53da207b479d","ea1ae702a3df405cafa2da5912631ec1"]}},"source":["model.eval()\n","eval_loss = 0\n","nb_eval_steps = 0\n","preds = []\n","\n","for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","    input_ids = input_ids.to(device)\n","    input_mask = input_mask.to(device)\n","    segment_ids = segment_ids.to(device)\n","    label_ids = label_ids.to(device)\n","\n","    with torch.no_grad():\n","        logits = model(input_ids, segment_ids, input_mask, labels=None)\n","\n","    # create eval loss and other metric required by the task\n","    if OUTPUT_MODE == \"classification\":\n","        loss_fct = CrossEntropyLoss()\n","        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n","    elif OUTPUT_MODE == \"regression\":\n","        loss_fct = MSELoss()\n","        tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n","\n","    eval_loss += tmp_eval_loss.mean().item()\n","    nb_eval_steps += 1\n","    if len(preds) == 0:\n","        preds.append(logits.detach().cpu().numpy())\n","    else:\n","        preds[0] = np.append(\n","            preds[0], logits.detach().cpu().numpy(), axis=0)\n","\n","eval_loss = eval_loss / nb_eval_steps\n","preds = preds[0]\n","\n","logger.info(\"***** Eval results *****\")\n","logger.info(\"eval_loss = %s\", eval_loss)\n","\n","# eval_loss = eval_loss / nb_eval_steps\n","# preds = preds[0]\n","# if OUTPUT_MODE == \"classification\":\n","#     preds = np.argmax(preds, axis=1)\n","# elif OUTPUT_MODE == \"regression\":\n","#     preds = np.squeeze(preds)\n","# result = compute_metrics(TASK_NAME, all_label_ids.numpy(), preds)\n","\n","# result['eval_loss'] = eval_loss\n","\n","# output_eval_file = os.path.join(REPORTS_DIR, \"eval_results.txt\")\n","# with open(output_eval_file, \"w\") as writer:\n","#     logger.info(\"***** Eval results *****\")\n","#     for key in (result.keys()):\n","#         logger.info(\"  %s = %s\", key, str(result[key]))\n","#         writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87c561b9bda945009b0f7c30a74aa4e8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Evaluating', max=1, style=ProgressStyle(description_width='in…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["INFO:root:***** Eval results *****\n","INFO:root:eval_loss = 8.440017700195312e-05\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qS5pmJQ6p_wL","colab_type":"code","colab":{}},"source":["from scipy.special import softmax\n","\n","pred_probs = softmax(preds, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEky50LMp_wM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}